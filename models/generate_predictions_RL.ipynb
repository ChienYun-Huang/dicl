{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_series_names = [\n",
    "    'brownian_motion',\n",
    "    'gym_halfcheetah',\n",
    "    'gym_halfcheetah_expert',\n",
    "]\n",
    "markov_chain_names = ['markov_chain']\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "### Set up directory\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(\"/home/abenechehab/llmICL/\")\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3,4,5\"\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import torch\n",
    "from llama import get_model_and_tokenizer\n",
    "from ICL import MultiResolutionPDF, recursive_refiner, trim_kv_cache\n",
    "\n",
    "# Check if directory exists, if not create it\n",
    "save_path = Path(parent_dir) / 'processed_series_RL'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "    \n",
    "# Define the directory where the generated series are stored\n",
    "generated_series_dir = Path(parent_dir) / 'generated_series_RL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_Markov(full_series, llama_size = '13b'):\n",
    "    '''\n",
    "     This function calculates the multi-resolution probability density function (PDF) for a given series.\n",
    "\n",
    "     Parameters:\n",
    "     full_series (str): The series for which the PDF is to be calculated.\n",
    "     llama_size (str, optional): The size of the llama model. Defaults to '13b'.\n",
    "\n",
    "     Returns:\n",
    "\n",
    "    '''\n",
    "    model, tokenizer = get_model_and_tokenizer(llama_size)\n",
    "    states = sorted(set(full_series))\n",
    "    good_tokens = [tokenizer.convert_tokens_to_ids(state) for state in states]\n",
    "    batch = tokenizer(\n",
    "        [full_series], \n",
    "        return_tensors=\"pt\",\n",
    "        add_special_tokens=True        \n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        out = model(batch['input_ids'].cpu())\n",
    "    logit_mat = out['logits']\n",
    "    logit_mat_good = logit_mat[:,:,good_tokens].cpu()\n",
    "\n",
    "    return logit_mat_good\n",
    "\n",
    "def calculate_multiPDF(full_series, prec, mode = 'neighbor', refine_depth = 1, llama_size = '13b', use_instruct = False):\n",
    "    '''\n",
    "     This function calculates the multi-resolution probability density function (PDF) for a given series.\n",
    "\n",
    "     Parameters:\n",
    "     full_series (str): The series for which the PDF is to be calculated.\n",
    "     prec (int): The precision of the PDF.\n",
    "     mode (str, optional): The mode of calculation. Defaults to 'neighbor'.\n",
    "     refine_depth (int, optional): The depth of refinement for the PDF. Defaults to 1.\n",
    "     llama_size (str, optional): The size of the llama model. Defaults to '13b'.\n",
    "\n",
    "     Returns:\n",
    "     list: A list of PDFs for the series.\n",
    "    '''\n",
    "    if llama_size != '13b':\n",
    "        assert False, \"Llama size must be '13b'\"\n",
    "    good_tokens_str = list(\"0123456789\")\n",
    "    print(f\"good_tokens_str: {good_tokens_str}\")\n",
    "    good_tokens = [tokenizer.convert_tokens_to_ids(token) for token in good_tokens_str]\n",
    "    print(f\"good_tokens: {good_tokens}\")\n",
    "    assert refine_depth < prec, \"Refine depth must be less than precision\"\n",
    "    refine_depth = refine_depth - prec\n",
    "    curr = -prec\n",
    "    batch = tokenizer(\n",
    "        [full_series], \n",
    "        return_tensors=\"pt\",\n",
    "        add_special_tokens=True        \n",
    "    )\n",
    "    print(f\"batch['input_ids']: shape | {batch['input_ids'].shape}, sample | {batch['input_ids'][0,:10]}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        out = model(batch['input_ids'].cuda(), use_cache=True)\n",
    "    print(f\"out: {list(out.keys())}\")\n",
    "    logit_mat = out['logits']\n",
    "    print(f\"logit_mat: shape | {logit_mat.shape}, sample | {logit_mat[:10]}\")\n",
    "    kv_cache_main = out['past_key_values']\n",
    "    logit_mat_good = logit_mat[:,:,good_tokens].clone()\n",
    "    print(f\"logit_mat_good: shape | {logit_mat_good.shape}, sample | {logit_mat_good[:10]}\")\n",
    "    probs = torch.nn.functional.softmax(logit_mat_good[:,1:,:], dim=-1)\n",
    "    \n",
    "    PDF_list = []\n",
    "    comma_locations = np.sort(np.where(np.array(list(full_series)) == ',')[0])\n",
    "\n",
    "    start_loop_from = 1 if use_instruct else 0\n",
    "    for i in tqdm(range(start_loop_from, len(comma_locations))):\n",
    "        PDF = MultiResolutionPDF()\n",
    "        # slice out the number before ith comma\n",
    "        if i == 0:\n",
    "            start_idx = 0\n",
    "        else:\n",
    "            start_idx = comma_locations[i-1]+1\n",
    "        end_idx = comma_locations[i]\n",
    "        num_slice = full_series[start_idx:end_idx]\n",
    "        prob_slice = probs[0,start_idx:end_idx].cpu().numpy()\n",
    "        ### Load hierarchical PDF \n",
    "        # print(f\"prob_slice: {prob_slice.shape}, type: {type(prob_slice)}\")\n",
    "        # print(f\"num_slice: {num_slice}, type: {type(num_slice)}\")\n",
    "        PDF.load_from_num_prob(num_slice, prob_slice)\n",
    "        \n",
    "        ### Refine hierarchical PDF\n",
    "        seq = full_series[:end_idx]\n",
    "        # cache and full_series are shifted from beginning, not end\n",
    "        end_idx_neg = end_idx - len(full_series)\n",
    "        ### kv cache contains seq[0:-1]\n",
    "        kv_cache = trim_kv_cache(kv_cache_main, end_idx_neg-1)\n",
    "        recursive_refiner(PDF, seq, curr = curr, main = True, refine_depth = refine_depth, mode = mode, \n",
    "                        kv_cache = kv_cache, model = model, tokenizer = tokenizer, good_tokens=good_tokens)\n",
    "\n",
    "        PDF_list += [PDF]\n",
    "\n",
    "        if i==10:\n",
    "            print(f\"start_idx: {start_idx}\")\n",
    "            print(f\"end_idx: {end_idx}\")\n",
    "            print(f\"num_slice: {num_slice}\")\n",
    "            print(f\"prob_slice: {prob_slice}\")\n",
    "            print(f\"PDF_list: shape | {len(PDF_list)}, sample | {PDF_list[:10]}\")\n",
    "        \n",
    "    # release memory\n",
    "    del logit_mat, kv_cache_main\n",
    "    return PDF_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c22e27333c74c03af9deead1bc89681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = get_model_and_tokenizer('7b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries to store the data for continuous series and Markov chains\n",
    "continuous_series_task = {}\n",
    "markov_chain_task = {}\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for file in generated_series_dir.iterdir():\n",
    "    # Check if a series is already processed\n",
    "    # if not (save_path / file.name).exists():\\\n",
    "    # Extract the series name from the file name\n",
    "    series_name = file.stem.rsplit('_', 1)[0]\n",
    "    # If the series is a continuous series, load the data into the continuous_series_data dictionary\n",
    "    if series_name in continuous_series_names:\n",
    "        continuous_series_task[file.name] = pickle.load(file.open('rb'))\n",
    "    # If the series is a Markov chain, load the data into the markov_chain_data dictionary\n",
    "    elif series_name in markov_chain_names:\n",
    "        markov_chain_task[file.name] = pickle.load(file.open('rb'))\n",
    "    # If the series name is not recognized, raise an exception\n",
    "    # else:\n",
    "    #     raise Exception(f\"Unrecognized series name: {series_name}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['gym_halfcheetah_15.pkl', 'gym_halfcheetah_5.pkl', 'gym_halfcheetah_expert_7.pkl', 'gym_halfcheetah_expert_16.pkl', 'brownian_motion_4.pkl', 'brownian_motion_14.pkl', 'gym_halfcheetah_9.pkl', 'gym_halfcheetah_0.pkl', 'gym_halfcheetah_expert_1.pkl', 'brownian_motion_13.pkl', 'brownian_motion_17.pkl', 'gym_halfcheetah_expert_14.pkl', 'gym_halfcheetah_expert_8.pkl', 'gym_halfcheetah_1.pkl', 'brownian_motion_7.pkl', 'gym_halfcheetah_expert_6.pkl', 'brownian_motion_11.pkl', 'gym_halfcheetah_expert_12.pkl', 'gym_halfcheetah_10.pkl', 'gym_halfcheetah_3.pkl', 'gym_halfcheetah_13.pkl', 'brownian_motion_10.pkl', 'brownian_motion_6.pkl', 'brownian_motion_21.pkl', 'brownian_motion_2.pkl', 'brownian_motion_5.pkl', 'gym_halfcheetah_8.pkl', 'brownian_motion_9.pkl', 'gym_halfcheetah_expert_11.pkl', 'gym_halfcheetah_6.pkl', 'gym_halfcheetah_expert_9.pkl', 'brownian_motion_16.pkl', 'gym_halfcheetah_12.pkl', 'gym_halfcheetah_expert_10.pkl', 'brownian_motion_15.pkl', 'brownian_motion_3.pkl', 'gym_halfcheetah_expert_13.pkl', 'brownian_motion_1.pkl', 'brownian_motion_18.pkl', 'brownian_motion_8.pkl', 'gym_halfcheetah_16.pkl', 'gym_halfcheetah_14.pkl', 'brownian_motion_19.pkl', 'gym_halfcheetah_expert_5.pkl', 'brownian_motion_0.pkl', 'gym_halfcheetah_7.pkl', 'gym_halfcheetah_2.pkl', 'gym_halfcheetah_expert_2.pkl', 'gym_halfcheetah_4.pkl', 'gym_halfcheetah_expert_0.pkl', 'gym_halfcheetah_expert_17.pkl', 'gym_halfcheetah_expert_4.pkl', 'brownian_motion_12.pkl', 'gym_halfcheetah_expert_3.pkl', 'brownian_motion_20.pkl', 'gym_halfcheetah_11.pkl', 'gym_halfcheetah_expert_15.pkl'])\n",
      "dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "print(continuous_series_task.keys())\n",
    "print(markov_chain_task.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Multi Digit series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  brownian_motion_0.pkl\n",
      "good_tokens_str: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "good_tokens: [29900, 29896, 29906, 29941, 29946, 29945, 29953, 29955, 29947, 29929]\n",
      "batch['input_ids']: shape | torch.Size([1, 4011]), sample | tensor([    1,  8500,   278,  2446,  1543,   310,   445,  3652,   310, 13917])\n",
      "out: ['logits', 'past_key_values']\n",
      "logit_mat: shape | torch.Size([1, 4011, 32000]), sample | tensor([[[ 0.1040, -0.2216,  0.3127,  ...,  1.3271,  1.8799,  0.6436],\n",
      "         [-8.8594, -7.1992, -1.0732,  ..., -5.7734, -9.5469, -6.6016],\n",
      "         [-4.5078, -1.9961,  1.8467,  ..., -0.0553, -2.0625, -2.6582],\n",
      "         ...,\n",
      "         [-5.2422, -4.8398,  5.3945,  ..., -3.4863, -4.6055, -2.6797],\n",
      "         [-1.6309,  0.4780, 10.1172,  ...,  0.5786, -1.4502,  0.0798],\n",
      "         [-4.5273, -4.5742,  6.6992,  ..., -2.5215, -1.7510, -1.7568]]],\n",
      "       device='cuda:0')\n",
      "logit_mat_good: shape | torch.Size([1, 4011, 10]), sample | tensor([[[ 0.3350, -0.0311,  0.2466,  ...,  0.2357,  0.3887,  0.1511],\n",
      "         [-0.9980, -0.3430,  0.2485,  ..., -1.7910, -2.1152, -1.9688],\n",
      "         [ 0.6846,  1.8828,  2.4512,  ...,  0.5444, -0.0659,  0.0943],\n",
      "         ...,\n",
      "         [17.1406, 16.7500, 17.1250,  ..., 18.1875, 17.9219, 18.2188],\n",
      "         [ 6.1328,  7.3359,  7.1250,  ...,  6.6953,  6.7539,  7.0195],\n",
      "         [ 5.2773,  8.7656, 10.7734,  ...,  7.2070,  6.9258,  6.3125]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                                       | 11/1000 [00:01<02:14,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_idx: 92\n",
      "end_idx: 95\n",
      "num_slice: 780\n",
      "prob_slice: [[2.55882367e-02 4.89387847e-02 4.08898853e-02 4.38684449e-02\n",
      "  9.35978740e-02 9.58174914e-02 4.78051230e-02 4.75329250e-01\n",
      "  6.48333579e-02 6.33314997e-02]\n",
      " [2.14069005e-05 8.01600982e-05 6.05080131e-05 3.39419203e-05\n",
      "  1.14824041e-04 2.39313827e-04 8.82239314e-04 9.98204350e-01\n",
      "  2.97830848e-04 6.54247633e-05]\n",
      " [1.68434897e-04 1.80704257e-04 1.30430318e-03 1.36977490e-02\n",
      "  2.58457571e-01 2.79459268e-01 2.54450560e-01 1.80432469e-01\n",
      "  1.05848005e-02 1.26417412e-03]]\n",
      "PDF_list: shape | 10, sample | [<ICL.MultiResolutionPDF object at 0x7f28238a8490>, <ICL.MultiResolutionPDF object at 0x7f28238a83d0>, <ICL.MultiResolutionPDF object at 0x7f28238b6ee0>, <ICL.MultiResolutionPDF object at 0x7f28238b9f40>, <ICL.MultiResolutionPDF object at 0x7f28238c4fd0>, <ICL.MultiResolutionPDF object at 0x7f28238b2f40>, <ICL.MultiResolutionPDF object at 0x7f28238c1f10>, <ICL.MultiResolutionPDF object at 0x7f2854770ee0>, <ICL.MultiResolutionPDF object at 0x7f26e0d17730>, <ICL.MultiResolutionPDF object at 0x7f28238bd0d0>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████████████████████████████████████████████▊                                      | 633/1000 [01:44<01:00,  6.05it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m llama_size \u001b[38;5;241m=\u001b[39m series_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllama_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m mode \u001b[38;5;241m=\u001b[39m series_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 10\u001b[0m PDF_list \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_multiPDF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_prompt\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mfull_series\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefine_depth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrefine_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllama_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mllama_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_instruct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m series_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPDF_list\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PDF_list\n\u001b[1;32m     12\u001b[0m save_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_path, series_name)\n",
      "Cell \u001b[0;32mIn[2], line 93\u001b[0m, in \u001b[0;36mcalculate_multiPDF\u001b[0;34m(full_series, prec, mode, refine_depth, llama_size, use_instruct)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m### kv cache contains seq[0:-1]\u001b[39;00m\n\u001b[1;32m     92\u001b[0m kv_cache \u001b[38;5;241m=\u001b[39m trim_kv_cache(kv_cache_main, end_idx_neg\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[43mrecursive_refiner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPDF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcurr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefine_depth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrefine_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m                \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgood_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgood_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m PDF_list \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [PDF]\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m10\u001b[39m:\n",
      "File \u001b[0;32m~/llmICL/models/ICL.py:43\u001b[0m, in \u001b[0;36mrecursive_refiner\u001b[0;34m(PDF, seq, curr, refine_depth, main, mode, model, tokenizer, good_tokens, kv_cache)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m alt_digit \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m     42\u001b[0m             alt_seq \u001b[38;5;241m=\u001b[39m trimmed_seq \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(alt_digit)\n\u001b[0;32m---> 43\u001b[0m             \u001b[43mrecursive_refiner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPDF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefine_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                              \u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgood_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgood_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrimmed_kv_cache\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# 9 off branches\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m curr \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/llmICL/models/ICL.py:66\u001b[0m, in \u001b[0;36mrecursive_refiner\u001b[0;34m(PDF, seq, curr, refine_depth, main, mode, model, tokenizer, good_tokens, kv_cache)\u001b[0m\n\u001b[1;32m     61\u001b[0m         recursive_refiner(PDF, seq, curr\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, refine_depth, mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     62\u001b[0m                           model \u001b[38;5;241m=\u001b[39m model, tokenizer \u001b[38;5;241m=\u001b[39m tokenizer, main \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, good_tokens\u001b[38;5;241m=\u001b[39mgood_tokens,\n\u001b[1;32m     63\u001b[0m                           kv_cache \u001b[38;5;241m=\u001b[39m kv_cache)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# ready to evaluate\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     probs, kv_cache_new \u001b[38;5;241m=\u001b[39m \u001b[43mnext_token_prob_from_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgood_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgood_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     last_comma_location \u001b[38;5;241m=\u001b[39m seq\u001b[38;5;241m.\u001b[39mrfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     68\u001b[0m     num_slice \u001b[38;5;241m=\u001b[39m seq[last_comma_location\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/llmICL/models/ICL.py:132\u001b[0m, in \u001b[0;36mnext_token_prob_from_series\u001b[0;34m(full_series, model, tokenizer, good_tokens, T, kv_cache, load_cache_to_cpu)\u001b[0m\n\u001b[1;32m    130\u001b[0m         kv_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mtuple\u001b[39m(x\u001b[38;5;241m.\u001b[39mcuda() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m sub_tuple) \u001b[38;5;28;01mfor\u001b[39;00m sub_tuple \u001b[38;5;129;01min\u001b[39;00m kv_cache)\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 132\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m logit_mat \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m'\u001b[39m] \n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_cache_to_cpu:\n",
      "File \u001b[0;32m~/miniforge3/envs/LLMICL/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/LLMICL/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/LLMICL/lib/python3.9/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniforge3/envs/LLMICL/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:1196\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1193\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1196\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1209\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/LLMICL/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/LLMICL/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/LLMICL/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:1016\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1006\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1007\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1013\u001b[0m         cache_position,\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1016\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniforge3/envs/LLMICL/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/LLMICL/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/LLMICL/lib/python3.9/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniforge3/envs/LLMICL/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:736\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    730\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    731\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing `padding_mask` is deprecated and will be removed in v4.37. Please make sure use `attention_mask` instead.`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    732\u001b[0m     )\n\u001b[1;32m    734\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 736\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m    739\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    740\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    741\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    748\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/LLMICL/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/LLMICL/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/LLMICL/lib/python3.9/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniforge3/envs/LLMICL/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py:87\u001b[0m, in \u001b[0;36mLlamaRMSNorm.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m     86\u001b[0m     input_dtype \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m---> 87\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     variance \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     89\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrsqrt(variance \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariance_epsilon)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pre_prompt = \"predict the next element of this series of observations,\"\n",
    "for series_name, series_dict in sorted(continuous_series_task.items()):\n",
    "    print(\"Processing \", series_name)\n",
    "    if series_name in ['brownian_motion_0.pkl']:\n",
    "        full_series = series_dict['full_series']\n",
    "        prec = series_dict['prec']\n",
    "        refine_depth = series_dict['refine_depth']\n",
    "        llama_size = series_dict['llama_size']\n",
    "        mode = series_dict['mode']\n",
    "        PDF_list = calculate_multiPDF(pre_prompt+full_series, prec, mode = mode, refine_depth = refine_depth, llama_size = llama_size, use_instruct=True)\n",
    "        series_dict['PDF_list'] = PDF_list\n",
    "        save_name = os.path.join(save_path, series_name)\n",
    "        with open(save_name, 'wb') as f:\n",
    "            pickle.dump(series_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_list[5].__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_list[5].sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Markov Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for series_name, series_dict in sorted(markov_chain_task.items()):\n",
    "    print(\"Processing \", series_name)\n",
    "    full_series = series_dict['full_series']\n",
    "    llama_size = series_dict['llama_size']\n",
    "    logit_mat_good = calculate_Markov(full_series, llama_size = llama_size)    \n",
    "    series_dict['logit_mat_good'] = logit_mat_good\n",
    "    save_name = os.path.join(save_path, series_name)\n",
    "    with open(save_name, 'wb') as f:\n",
    "        pickle.dump(series_dict, f)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = [4,2,6,10,5,3,4,2,1,2]\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.bar(x=np.arange(len(bins)), height=np.array(bins)/sum(bins), width=1.0)\n",
    "plt.grid(True)\n",
    "two_bins = []\n",
    "for i, b in enumerate(bins):\n",
    "    if i in [3]:\n",
    "        two_bins += bins\n",
    "    else:\n",
    "        two_bins += [b]*10\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.bar(x=np.arange(len(two_bins)), height=np.array(two_bins)/sum(two_bins), width=1.0)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:LLMICL]",
   "language": "python",
   "name": "conda-env-LLMICL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
