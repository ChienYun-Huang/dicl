{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_series_names = [\n",
    "                           'brownian_motion', \n",
    "                           # 'geometric_brownian_motion',\n",
    "                           # 'noisy_logistic_map',\n",
    "                           # 'logistic_map',\n",
    "                           # 'lorenz_system',\n",
    "                           # 'uncorrelated_gaussian',\n",
    "                           # 'uncorrelated_uniform'\n",
    "                           ]\n",
    "markov_chain_names = ['markov_chain']\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "### Set up directory\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3,4,5\"\n",
    "from pathlib import Path\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import torch\n",
    "from llama import get_model_and_tokenizer\n",
    "from ICL import MultiResolutionPDF, recursive_refiner, trim_kv_cache, recursive_refiner_preprompt\n",
    "\n",
    "# Check if directory exists, if not create it\n",
    "save_path = Path(parent_dir) / 'processed_series_v2'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "    \n",
    "# Define the directory where the generated series are stored\n",
    "generated_series_dir = Path(parent_dir) / 'generated_series'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_Markov(full_series, llama_size = '13b'):\n",
    "    '''\n",
    "     This function calculates the multi-resolution probability density function (PDF) for a given series.\n",
    "\n",
    "     Parameters:\n",
    "     full_series (str): The series for which the PDF is to be calculated.\n",
    "     llama_size (str, optional): The size of the llama model. Defaults to '13b'.\n",
    "\n",
    "     Returns:\n",
    "\n",
    "    '''\n",
    "    model, tokenizer = get_model_and_tokenizer(llama_size)\n",
    "    states = sorted(set(full_series))\n",
    "    good_tokens = [tokenizer.convert_tokens_to_ids(state) for state in states]\n",
    "    batch = tokenizer(\n",
    "        [full_series], \n",
    "        return_tensors=\"pt\",\n",
    "        add_special_tokens=True,        \n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        out = model(batch['input_ids'].cpu())\n",
    "    logit_mat = out['logits']\n",
    "    logit_mat_good = logit_mat[:,:,good_tokens].cpu()\n",
    "\n",
    "    return logit_mat_good\n",
    "\n",
    "def calculate_multiPDF(\n",
    "    full_series, prec, mode = 'neighbor', refine_depth = 1, llama_size = '13b', size_preprompt = 0,\n",
    "    number_of_tokens_original = None\n",
    "):\n",
    "    '''\n",
    "     This function calculates the multi-resolution probability density function (PDF) for a given series.\n",
    "\n",
    "     Parameters:\n",
    "     full_series (str): The series for which the PDF is to be calculated.\n",
    "     prec (int): The precision of the PDF.\n",
    "     mode (str, optional): The mode of calculation. Defaults to 'neighbor'.\n",
    "     refine_depth (int, optional): The depth of refinement for the PDF. Defaults to 1.\n",
    "     llama_size (str, optional): The size of the llama model. Defaults to '13b'.\n",
    "\n",
    "     Returns:\n",
    "     list: A list of PDFs for the series.\n",
    "    '''\n",
    "    # if llama_size != '13b':\n",
    "    #     assert False, \"Llama size must be '13b'\"\n",
    "    good_tokens_str = list(\"0123456789\")\n",
    "    print(f\"good_tokens_str: {good_tokens_str}\")\n",
    "    good_tokens = [tokenizer.convert_tokens_to_ids(token) for token in good_tokens_str]\n",
    "    print(f\"good_tokens: {good_tokens}\")\n",
    "    assert refine_depth < prec, \"Refine depth must be less than precision\"\n",
    "    refine_depth = refine_depth - prec\n",
    "    curr = -prec\n",
    "    batch = tokenizer(\n",
    "        [full_series], \n",
    "        return_tensors=\"pt\",\n",
    "        add_special_tokens=True        \n",
    "    )\n",
    "    print(f\"batch['input_ids']: shape | {batch['input_ids'].shape}, sample | {batch['input_ids'][0,:10]}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    with torch.no_grad():\n",
    "        out = model(batch['input_ids'].cuda(), use_cache=True)\n",
    "    print(f\"out: {list(out.keys())}\")\n",
    "    logit_mat = out['logits']\n",
    "    print(f\"logit_mat: shape | {logit_mat.shape}, sample | {logit_mat[:10]}\")\n",
    "    kv_cache_main = out['past_key_values']\n",
    "    logit_mat_good = logit_mat[:,:,good_tokens].clone()\n",
    "    print(f\"logit_mat_good: shape | {logit_mat_good.shape}, sample | {logit_mat_good[:10]}\")\n",
    "    probs = torch.nn.functional.softmax(logit_mat_good[:,1:,:], dim=-1)\n",
    "    \n",
    "    PDF_list = []\n",
    "    comma_locations = np.sort(np.where(np.array(list(full_series[size_preprompt:])) == ',')[0])\n",
    "    \n",
    "    print(f\"len coma locations: {comma_locations.shape} | sample: {comma_locations[:10]}\")\n",
    "    print(f\"probs: {probs.shape}, type: {type(probs)}\")\n",
    "    # start_loop_from = 1 if use_instruct else 0\n",
    "    for i in tqdm(range(len(comma_locations))):\n",
    "        PDF = MultiResolutionPDF()\n",
    "        # slice out the number before ith comma\n",
    "        if i == 0:\n",
    "            start_idx = 0\n",
    "        else:\n",
    "            start_idx = comma_locations[i-1]+1\n",
    "        end_idx = comma_locations[i]\n",
    "        # print(f\"start_idx:end_idx {start_idx}:{end_idx}\")\n",
    "        # if end_idx <= probs.shape[1]:\n",
    "        num_slice = full_series[size_preprompt:][start_idx:end_idx]\n",
    "        if number_of_tokens_original:\n",
    "            prob_slice = probs[:,-(number_of_tokens_original-1):][0,start_idx:end_idx].cpu().numpy()\n",
    "        else:\n",
    "            prob_slice = probs[0,start_idx:end_idx].cpu().numpy()\n",
    "        ### Load hierarchical PDF \n",
    "        # print(f\"prob_slice: {prob_slice.shape}, type: {type(prob_slice)}, sample: {prob_slice[:10]}\")\n",
    "        # print(f\"num_slice: {num_slice}, type: {type(num_slice)}\")\n",
    "        PDF.load_from_num_prob(num_slice, prob_slice)\n",
    "\n",
    "        # raise ValueError('test')\n",
    "        \n",
    "        ### Refine hierarchical PDF\n",
    "        seq = full_series[:size_preprompt+end_idx]\n",
    "        # cache and full_series are shifted from beginning, not end\n",
    "        end_idx_neg = end_idx - len(full_series[size_preprompt:])\n",
    "        ### kv cache contains seq[0:-1]\n",
    "        kv_cache = trim_kv_cache(kv_cache_main, end_idx_neg-1)\n",
    "        # recursive_refiner_preprompt(\n",
    "        #     PDF, seq, curr=curr, main=True, refine_depth=refine_depth, mode=mode, \n",
    "        #     kv_cache=kv_cache, model=model, tokenizer=tokenizer, good_tokens=good_tokens,\n",
    "        #     size_preprompt=size_preprompt\n",
    "        # )\n",
    "        recursive_refiner(\n",
    "            PDF, seq, curr=curr, main=True, refine_depth=refine_depth, mode=mode, \n",
    "            kv_cache=kv_cache, model=model, tokenizer=tokenizer, good_tokens=good_tokens,\n",
    "        )\n",
    "\n",
    "        PDF_list += [PDF]\n",
    "\n",
    "        raise ValueError(\"test\")\n",
    "\n",
    "        if i==10:\n",
    "            print(f\"start_idx: {start_idx}\")\n",
    "            print(f\"end_idx: {end_idx}\")\n",
    "            print(f\"num_slice: {num_slice}\")\n",
    "            print(f\"prob_slice: {prob_slice}\")\n",
    "            print(f\"PDF_list: shape | {len(PDF_list)}, sample | {PDF_list[:10]}\")\n",
    "    \n",
    "    # release memory\n",
    "    del logit_mat, kv_cache_main\n",
    "    return PDF_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7079a1f8ce31421795620f4b460f64c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = get_model_and_tokenizer('7b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries to store the data for continuous series and Markov chains\n",
    "continuous_series_task = {}\n",
    "markov_chain_task = {}\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for file in generated_series_dir.iterdir():\n",
    "    # Check if a series is already processed\n",
    "    # if not (save_path / file.name).exists():\\\n",
    "    # Extract the series name from the file name\n",
    "    series_name = file.stem.rsplit('_', 1)[0]\n",
    "    # If the series is a continuous series, load the data into the continuous_series_data dictionary\n",
    "    if series_name in continuous_series_names:\n",
    "        continuous_series_task[file.name] = pickle.load(file.open('rb'))\n",
    "    # If the series is a Markov chain, load the data into the markov_chain_data dictionary\n",
    "    elif series_name in markov_chain_names:\n",
    "        markov_chain_task[file.name] = pickle.load(file.open('rb'))\n",
    "    # If the series name is not recognized, raise an exception\n",
    "    # else:\n",
    "    #     raise Exception(f\"Unrecognized series name: {series_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['brownian_motion_4.pkl', 'brownian_motion_14.pkl', 'brownian_motion_13.pkl', 'brownian_motion_17.pkl', 'brownian_motion_7.pkl', 'brownian_motion_11.pkl', 'brownian_motion_10.pkl', 'brownian_motion_6.pkl', 'brownian_motion_2.pkl', 'brownian_motion_5.pkl', 'brownian_motion_9.pkl', 'brownian_motion_16.pkl', 'brownian_motion_15.pkl', 'brownian_motion_3.pkl', 'brownian_motion_1.pkl', 'brownian_motion_18.pkl', 'brownian_motion_8.pkl', 'brownian_motion_19.pkl', 'brownian_motion_0.pkl', 'brownian_motion_12.pkl'])\n",
      "dict_keys(['markov_chain_8.pkl', 'markov_chain_7.pkl', 'markov_chain_4.pkl', 'markov_chain_3.pkl', 'markov_chain_10.pkl', 'markov_chain_0.pkl', 'markov_chain_14.pkl', 'markov_chain_5.pkl', 'markov_chain_11.pkl', 'markov_chain_6.pkl', 'markov_chain_12.pkl', 'markov_chain_13.pkl', 'markov_chain_9.pkl', 'markov_chain_17.pkl', 'markov_chain_15.pkl', 'markov_chain_1.pkl', 'markov_chain_16.pkl', 'markov_chain_2.pkl'])\n"
     ]
    }
   ],
   "source": [
    "print(continuous_series_task.keys())\n",
    "print(markov_chain_task.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Multi Digit series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  brownian_motion_0.pkl\n",
      "full_series: 214,223,21\n",
      "number_of_tokens_original: None\n",
      "comma token: [1, 1919]\n",
      "good_tokens_str: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "good_tokens: [29900, 29896, 29906, 29941, 29946, 29945, 29953, 29955, 29947, 29929]\n",
      "batch['input_ids']: shape | torch.Size([1, 4002]), sample | tensor([    1, 29871, 29906, 29896, 29946, 29892, 29906, 29906, 29941, 29892])\n",
      "out: ['logits', 'past_key_values']\n",
      "logit_mat: shape | torch.Size([1, 4002, 32000]), sample | tensor([[[ 0.1040, -0.2216,  0.3127,  ...,  1.3271,  1.8799,  0.6436],\n",
      "         [-2.3770,  7.4023,  9.1172,  ...,  4.3398, -0.2791,  3.2949],\n",
      "         [-9.1719, -5.5156,  0.6323,  ..., -4.8477, -8.5547, -3.3789],\n",
      "         ...,\n",
      "         [-5.7305, -6.2188,  6.3438,  ..., -3.5723, -4.5273, -2.7539],\n",
      "         [-2.0762, -0.5918, 10.5625,  ...,  0.8237, -1.3496, -1.8525],\n",
      "         [-3.5195, -1.6318,  7.4961,  ..., -0.3696, -2.3652, -1.4277]]],\n",
      "       device='cuda:0')\n",
      "logit_mat_good: shape | torch.Size([1, 4002, 10]), sample | tensor([[[ 0.3350, -0.0311,  0.2466,  ...,  0.2357,  0.3887,  0.1511],\n",
      "         [11.0078, 12.6875, 12.3672,  ...,  9.9531, 10.1094,  9.8203],\n",
      "         [13.0000,  9.6172,  9.3984,  ...,  8.9844,  8.9219,  8.1328],\n",
      "         ...,\n",
      "         [16.2188, 16.0469, 16.1562,  ..., 16.2344, 15.8516, 15.7344],\n",
      "         [ 6.5859,  6.9570,  6.7617,  ...,  7.1055,  6.8477,  6.9102],\n",
      "         [ 6.0469,  8.9922,  8.3281,  ..., 14.5312, 19.4688, 12.1328]]],\n",
      "       device='cuda:0')\n",
      "len coma locations: (1000,) | sample: [ 3  7 11 15 19 23 27 31 35 39]\n",
      "probs: torch.Size([1, 4001, 10]), type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                  | 0/1000 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "test",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber_of_tokens_original: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumber_of_tokens_original\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomma token: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m PDF_list \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_multiPDF\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_prompt\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mfull_series\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefine_depth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrefine_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllama_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mllama_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize_preprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpre_prompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_tokens_original\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumber_of_tokens_original\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m series_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPDF_list\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PDF_list\n\u001b[1;32m     22\u001b[0m save_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseries_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_llama3_raw.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 117\u001b[0m, in \u001b[0;36mcalculate_multiPDF\u001b[0;34m(full_series, prec, mode, refine_depth, llama_size, size_preprompt, number_of_tokens_original)\u001b[0m\n\u001b[1;32m    110\u001b[0m recursive_refiner(\n\u001b[1;32m    111\u001b[0m     PDF, seq, curr\u001b[38;5;241m=\u001b[39mcurr, main\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, refine_depth\u001b[38;5;241m=\u001b[39mrefine_depth, mode\u001b[38;5;241m=\u001b[39mmode, \n\u001b[1;32m    112\u001b[0m     kv_cache\u001b[38;5;241m=\u001b[39mkv_cache, model\u001b[38;5;241m=\u001b[39mmodel, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, good_tokens\u001b[38;5;241m=\u001b[39mgood_tokens,\n\u001b[1;32m    113\u001b[0m )\n\u001b[1;32m    115\u001b[0m PDF_list \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [PDF]\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m10\u001b[39m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_idx: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: test"
     ]
    }
   ],
   "source": [
    "# pre_prompt = \"Brownian Motion,\"\n",
    "pre_prompt = \"\"\n",
    "number_of_tokens_original = None\n",
    "for series_name, series_dict in sorted(continuous_series_task.items()):\n",
    "    print(\"Processing \", series_name)\n",
    "    if 'brownian_motion' in series_name:\n",
    "        full_series = series_dict['full_series']\n",
    "        print(f\"full_series: {full_series[:10]}\")\n",
    "        prec = series_dict['prec']\n",
    "        refine_depth = series_dict['refine_depth']\n",
    "        llama_size = series_dict['llama_size']\n",
    "        mode = series_dict['mode']\n",
    "        if len(pre_prompt) > 1:\n",
    "            number_of_tokens_original = len(tokenizer(full_series)['input_ids'])\n",
    "        print(f\"number_of_tokens_original: {number_of_tokens_original}\")\n",
    "        print(f\"comma token: {tokenizer(',')['input_ids']}\")\n",
    "        PDF_list = calculate_multiPDF(\n",
    "            pre_prompt+full_series, prec, mode = mode, refine_depth = refine_depth, llama_size = llama_size, \n",
    "            size_preprompt=len(pre_prompt), number_of_tokens_original=number_of_tokens_original\n",
    "        )\n",
    "        series_dict['PDF_list'] = PDF_list\n",
    "        save_name = os.path.join(save_path, f\"{series_name.split('.')[0]}_llama3_raw.pkl\")\n",
    "        # save_name = os.path.join(save_path, series_name)\n",
    "        with open(save_name, 'wb') as f:\n",
    "            pickle.dump(series_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_1477006/569063534.py\u001b[0m(117)\u001b[0;36mcalculate_multiPDF\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    115 \u001b[0;31m        \u001b[0mPDF_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mPDF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    116 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 117 \u001b[0;31m        \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    118 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    119 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  PDF.bin_height_arr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([6.94085172e-02, 6.03808161e+00, 1.28056978e+00, 4.17367299e-01,\n",
      "       4.87951789e-01, 3.16278424e-01, 6.85439545e-01, 4.04526239e-01,\n",
      "       3.13817108e-01, 3.11374967e-01, 2.27806796e-01, 4.96871468e-01,\n",
      "       4.43656301e-01, 2.84216888e-01, 2.75472458e-01, 1.79954925e-01,\n",
      "       4.10314969e-01, 2.17067074e-01, 2.00754210e-01, 1.23198901e-01,\n",
      "       1.24651135e-01, 6.72958998e-01, 3.65881426e-01, 2.44683522e-01,\n",
      "       1.08806169e+00, 2.03643686e-01, 5.64478968e-01, 2.70839970e-01,\n",
      "       2.24534227e-01, 1.98926298e-01, 1.44970200e-01, 3.63286818e-01,\n",
      "       2.53615063e-01, 1.96745568e-01, 2.26452765e-01, 1.56859246e-01,\n",
      "       2.79631832e-01, 1.95978539e-01, 1.45071090e-01, 1.11229862e-01,\n",
      "       1.19332227e-01, 3.63272254e-01, 2.45802300e-01, 1.89941305e-01,\n",
      "       2.22063872e-01, 1.79832808e-01, 2.60635100e-01, 2.02191466e-01,\n",
      "       1.47926437e-01, 1.24080911e-01, 1.28520713e-01, 1.16857122e+00,\n",
      "       2.66926834e-01, 2.13645560e-01, 2.60743492e-01, 1.87806488e-01,\n",
      "       3.45428989e-01, 2.32817733e-01, 1.69669013e-01, 1.40660562e-01,\n",
      "       1.36866476e-01, 3.33202731e-01, 2.13457678e-01, 1.82580029e-01,\n",
      "       1.79749386e-01, 1.50186247e-01, 1.94355441e-01, 1.78350573e-01,\n",
      "       1.08175088e-01, 1.63025610e-01, 9.03836654e-02, 2.48116686e-01,\n",
      "       1.24760901e-01, 1.10532043e-01, 1.28721245e-01, 1.00248202e-01,\n",
      "       2.09752950e-01, 1.52860256e-01, 1.20450979e-01, 1.14487038e-01,\n",
      "       1.08818395e-01, 3.61378352e-01, 2.35153348e-01, 2.35153348e-01,\n",
      "       2.30605092e-01, 1.98018989e-01, 3.40812235e-01, 4.00009357e-01,\n",
      "       3.13970948e-01, 3.81691600e-01, 3.06697820e-01, 2.91664494e-01,\n",
      "       4.55281800e-01, 5.19948158e-01, 5.03951039e-01, 4.01784783e-01,\n",
      "       7.05154266e-01, 8.91398534e-01, 7.38995390e-01, 1.01800907e+00,\n",
      "       1.03404040e+00, 1.10949395e+00, 1.46147162e+01, 6.04490953e+00,\n",
      "       2.14633495e-02, 1.64565204e-02, 2.67115695e-02, 2.06411005e-02,\n",
      "       1.52197929e-02, 1.44098097e-02, 1.17609451e-02, 1.35094529e-01,\n",
      "       9.84519384e-02, 9.73049466e-02, 5.83308414e-02, 5.18805272e-02,\n",
      "       1.00786654e-01, 7.37371013e-02, 4.66874209e-02, 4.02470709e-02,\n",
      "       4.08808703e-02, 1.24513666e-01, 7.26281833e-02, 6.16387344e-02,\n",
      "       5.92773891e-02, 3.97969576e-02, 8.16580541e-02, 5.25168578e-02,\n",
      "       3.66626751e-02, 3.53961472e-02, 3.32516051e-02, 1.25216602e-01,\n",
      "       6.72859391e-02, 5.64395469e-02, 6.80790831e-02, 4.69731573e-02,\n",
      "       7.33240615e-02, 5.86878413e-02, 4.16159126e-02, 3.68696533e-02,\n",
      "       3.70139555e-02, 1.87803942e-01, 7.12823374e-02, 6.85515516e-02,\n",
      "       5.50827232e-02, 5.52983076e-02, 7.44120079e-02, 6.90892113e-02,\n",
      "       1.32653744e-01, 5.07445794e-02, 3.26354325e-02, 4.04213569e-01,\n",
      "       6.52172910e-02, 6.96951595e-02, 6.10271195e-02, 4.84653726e-02,\n",
      "       1.00224448e-01, 8.24423851e-02, 4.62459816e-02, 3.60164077e-02,\n",
      "       3.35709837e-02, 1.03914767e-01, 5.43330961e-02, 5.16428789e-02,\n",
      "       4.23146593e-02, 4.13344399e-02, 6.32741728e-02, 5.04465703e-02,\n",
      "       3.33431462e-02, 3.09580628e-02, 2.75346704e-02, 9.62063853e-02,\n",
      "       3.82682576e-02, 3.75280809e-02, 3.24778462e-02, 2.75635909e-02,\n",
      "       5.39668886e-02, 3.76749619e-02, 2.63013617e-02, 2.29404562e-02,\n",
      "       2.18899354e-02, 8.84917594e-02, 3.49256655e-02, 3.68888524e-02,\n",
      "       2.87290663e-02, 2.89543937e-02, 4.77377203e-02, 3.31963753e-02,\n",
      "       2.35397560e-02, 2.92956983e-02, 1.91376853e-02, 2.93175729e-02,\n",
      "       1.87815423e-02, 1.86353829e-02, 1.59396874e-02, 1.29588751e-02,\n",
      "       2.31921076e-02, 1.47418014e-02, 1.11712476e-02, 1.10410988e-02,\n",
      "       1.27082272e-02, 1.11557513e+00, 1.99231827e-01, 9.41104547e-02,\n",
      "       1.29137199e-01, 6.83168593e-02, 1.34806990e-01, 9.08593649e-02,\n",
      "       6.41777517e-02, 6.29364428e-02, 6.34300602e-02, 1.72962927e-01,\n",
      "       2.10269444e-01, 1.16576304e-01, 1.10372226e-01, 6.07156937e-02,\n",
      "       1.45081555e-01, 8.23426960e-02, 8.26649760e-02, 6.36295068e-02,\n",
      "       3.79949115e-02, 1.24644128e-01, 8.94277887e-02, 6.26750043e-02,\n",
      "       5.61815103e-02, 4.56752446e-02, 7.98500226e-02, 6.00389747e-02,\n",
      "       3.68447328e-02, 4.19139610e-02, 3.67010897e-02, 1.18943150e-01,\n",
      "       7.80048236e-02, 6.00424556e-02, 1.08298975e-01, 4.27431183e-02,\n",
      "       8.40144983e-02, 6.54305609e-02, 4.49697233e-02, 3.89180501e-02,\n",
      "       3.87663227e-02, 8.04063199e-02, 4.56355274e-02, 3.91869113e-02,\n",
      "       5.13094034e-02, 2.71439788e-02, 5.37717917e-02, 3.73924112e-02,\n",
      "       2.72502158e-02, 2.13055525e-02, 2.11397530e-02, 3.65885812e-01,\n",
      "       7.82064782e-02, 6.90169784e-02, 6.21085585e-02, 3.42996021e-02,\n",
      "       8.62291913e-02, 5.27108517e-02, 3.91713745e-02, 3.76707434e-02,\n",
      "       2.77766652e-02, 5.57912745e-01, 2.42273915e-02, 1.41870213e-02,\n",
      "       1.57036021e-02, 1.27669373e-02, 1.42168802e-01, 2.33904449e-02,\n",
      "       1.06671755e-02, 1.14442097e-02, 7.92717181e-03, 8.36568419e-02,\n",
      "       4.40840611e-02, 3.96713560e-02, 4.20653017e-02, 2.49228664e-02,\n",
      "       6.12046568e-02, 3.78546753e-02, 2.74795464e-02, 2.70535141e-02,\n",
      "       2.13176574e-02, 6.31252484e-02, 3.11274353e-02, 2.86759360e-02,\n",
      "       2.55049061e-02, 2.12270664e-02, 3.71094162e-02, 2.60079437e-02,\n",
      "       1.69899307e-02, 1.91022929e-02, 1.35455535e-02, 3.57696195e-02,\n",
      "       2.11101742e-02, 1.98311744e-02, 2.23840567e-02, 1.45655837e-02,\n",
      "       2.65817229e-02, 1.92962617e-02, 1.25563177e-02, 1.31589086e-02,\n",
      "       1.42281722e-02, 5.03851760e-02, 6.03031622e-02, 2.98522279e-02,\n",
      "       2.41750733e-02, 2.82635238e-02, 2.11684007e-02])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit()\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Markov Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  markov_chain_0.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.89s/it]\n"
     ]
    }
   ],
   "source": [
    "for series_name, series_dict in sorted(markov_chain_task.items()):\n",
    "    print(\"Processing \", series_name)\n",
    "    full_series = series_dict['full_series']\n",
    "    llama_size = series_dict['llama_size']\n",
    "    logit_mat_good = calculate_Markov(full_series, llama_size = llama_size)    \n",
    "    series_dict['logit_mat_good'] = logit_mat_good\n",
    "    save_name = os.path.join(save_path, series_name)\n",
    "    with open(save_name, 'wb') as f:\n",
    "        pickle.dump(series_dict, f)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n",
       "       0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21,\n",
       "       0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32,\n",
       "       0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
       "       0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
       "       0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
       "       0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
       "       0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
       "       0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
       "       0.99, 1.  , 1.01, 1.02, 1.03, 1.04, 1.05, 1.06, 1.07, 1.08, 1.09,\n",
       "       1.1 , 1.11, 1.12, 1.13, 1.14, 1.15, 1.16, 1.17, 1.18, 1.19, 1.2 ,\n",
       "       1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3 , 1.31,\n",
       "       1.32, 1.33, 1.34, 1.35, 1.36, 1.37, 1.38, 1.39, 1.4 , 1.41, 1.42,\n",
       "       1.43, 1.44, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5 , 1.51, 1.52, 1.53,\n",
       "       1.54, 1.55, 1.56, 1.57, 1.58, 1.59, 1.6 , 1.61, 1.62, 1.63, 1.64,\n",
       "       1.65, 1.66, 1.67, 1.68, 1.69, 1.7 , 1.71, 1.72, 1.73, 1.74, 1.75,\n",
       "       1.76, 1.77, 1.78, 1.79, 1.8 , 1.81, 1.82, 1.83, 1.84, 1.85, 1.86,\n",
       "       1.87, 1.88, 1.89, 1.9 , 1.91, 1.92, 1.93, 1.94, 1.95, 1.96, 1.97,\n",
       "       1.98, 1.99, 2.  , 2.01, 2.02, 2.03, 2.04, 2.05, 2.06, 2.07, 2.08,\n",
       "       2.09, 2.1 , 2.11, 2.12, 2.13, 2.14, 2.15, 2.16, 2.17, 2.18, 2.19,\n",
       "       2.2 , 2.21, 2.22, 2.23, 2.24, 2.25, 2.26, 2.27, 2.28, 2.29, 2.3 ,\n",
       "       2.31, 2.32, 2.33, 2.34, 2.35, 2.36, 2.37, 2.38, 2.39, 2.4 , 2.41,\n",
       "       2.42, 2.43, 2.44, 2.45, 2.46, 2.47, 2.48, 2.49, 2.5 , 2.51, 2.52,\n",
       "       2.53, 2.54, 2.55, 2.56, 2.57, 2.58, 2.59, 2.6 , 2.61, 2.62, 2.63,\n",
       "       2.64, 2.65, 2.66, 2.67, 2.68, 2.69, 2.7 , 2.71, 2.72, 2.73, 2.74,\n",
       "       2.75, 2.76, 2.77, 2.78, 2.79, 2.8 , 2.81, 2.82, 2.83, 2.84, 2.85,\n",
       "       2.86, 2.87, 2.88, 2.89, 2.9 , 2.91, 2.92, 2.93, 2.94, 2.95, 2.96,\n",
       "       2.97, 2.98, 2.99, 3.  , 3.01, 3.02, 3.03, 3.04, 3.05, 3.06, 3.07,\n",
       "       3.08, 3.09, 3.1 , 3.11, 3.12, 3.13, 3.14, 3.15, 3.16, 3.17, 3.18,\n",
       "       3.19, 3.2 , 3.21, 3.22, 3.23, 3.24, 3.25, 3.26, 3.27, 3.28, 3.29,\n",
       "       3.3 , 3.31, 3.32, 3.33, 3.34, 3.35, 3.36, 3.37, 3.38, 3.39, 3.4 ,\n",
       "       3.41, 3.42, 3.43, 3.44, 3.45, 3.46, 3.47, 3.48, 3.49, 3.5 , 3.51,\n",
       "       3.52, 3.53, 3.54, 3.55, 3.56, 3.57, 3.58, 3.59, 3.6 , 3.61, 3.62,\n",
       "       3.63, 3.64, 3.65, 3.66, 3.67, 3.68, 3.69, 3.7 , 3.71, 3.72, 3.73,\n",
       "       3.74, 3.75, 3.76, 3.77, 3.78, 3.79, 3.8 , 3.81, 3.82, 3.83, 3.84,\n",
       "       3.85, 3.86, 3.87, 3.88, 3.89, 3.9 , 3.91, 3.92, 3.93, 3.94, 3.95,\n",
       "       3.96, 3.97, 3.98, 3.99, 4.  , 4.01, 4.02, 4.03, 4.04, 4.05, 4.06,\n",
       "       4.07, 4.08, 4.09, 4.1 , 4.11, 4.12, 4.13, 4.14, 4.15, 4.16, 4.17,\n",
       "       4.18, 4.19, 4.2 , 4.21, 4.22, 4.23, 4.24, 4.25, 4.26, 4.27, 4.28,\n",
       "       4.29, 4.3 , 4.31, 4.32, 4.33, 4.34, 4.35, 4.36, 4.37, 4.38, 4.39,\n",
       "       4.4 , 4.41, 4.42, 4.43, 4.44, 4.45, 4.46, 4.47, 4.48, 4.49, 4.5 ,\n",
       "       4.51, 4.52, 4.53, 4.54, 4.55, 4.56, 4.57, 4.58, 4.59, 4.6 , 4.61,\n",
       "       4.62, 4.63, 4.64, 4.65, 4.66, 4.67, 4.68, 4.69, 4.7 , 4.71, 4.72,\n",
       "       4.73, 4.74, 4.75, 4.76, 4.77, 4.78, 4.79, 4.8 , 4.81, 4.82, 4.83,\n",
       "       4.84, 4.85, 4.86, 4.87, 4.88, 4.89, 4.9 , 4.91, 4.92, 4.93, 4.94,\n",
       "       4.95, 4.96, 4.97, 4.98, 4.99, 5.  , 5.01, 5.02, 5.03, 5.04, 5.05,\n",
       "       5.06, 5.07, 5.08, 5.09, 5.1 , 5.11, 5.12, 5.13, 5.14, 5.15, 5.16,\n",
       "       5.17, 5.18, 5.19, 5.2 , 5.21, 5.22, 5.23, 5.24, 5.25, 5.26, 5.27,\n",
       "       5.28, 5.29, 5.3 , 5.31, 5.32, 5.33, 5.34, 5.35, 5.36, 5.37, 5.38,\n",
       "       5.39, 5.4 , 5.41, 5.42, 5.43, 5.44, 5.45, 5.46, 5.47, 5.48, 5.49,\n",
       "       5.5 , 5.51, 5.52, 5.53, 5.54, 5.55, 5.56, 5.57, 5.58, 5.59, 5.6 ,\n",
       "       5.61, 5.62, 5.63, 5.64, 5.65, 5.66, 5.67, 5.68, 5.69, 5.7 , 5.71,\n",
       "       5.72, 5.73, 5.74, 5.75, 5.76, 5.77, 5.78, 5.79, 5.8 , 5.81, 5.82,\n",
       "       5.83, 5.84, 5.85, 5.86, 5.87, 5.88, 5.89, 5.9 , 5.91, 5.92, 5.93,\n",
       "       5.94, 5.95, 5.96, 5.97, 5.98, 5.99, 6.  , 6.01, 6.02, 6.03, 6.04,\n",
       "       6.05, 6.06, 6.07, 6.08, 6.09, 6.1 , 6.11, 6.12, 6.13, 6.14, 6.15,\n",
       "       6.16, 6.17, 6.18, 6.19, 6.2 , 6.21, 6.22, 6.23, 6.24, 6.25, 6.26,\n",
       "       6.27, 6.28, 6.29, 6.3 , 6.31, 6.32, 6.33, 6.34, 6.35, 6.36, 6.37,\n",
       "       6.38, 6.39, 6.4 , 6.41, 6.42, 6.43, 6.44, 6.45, 6.46, 6.47, 6.48,\n",
       "       6.49, 6.5 , 6.51, 6.52, 6.53, 6.54, 6.55, 6.56, 6.57, 6.58, 6.59,\n",
       "       6.6 , 6.61, 6.62, 6.63, 6.64, 6.65, 6.66, 6.67, 6.68, 6.69, 6.7 ,\n",
       "       6.71, 6.72, 6.73, 6.74, 6.75, 6.76, 6.77, 6.78, 6.79, 6.8 , 6.81,\n",
       "       6.82, 6.83, 6.84, 6.85, 6.86, 6.87, 6.88, 6.89, 6.9 , 6.91, 6.92,\n",
       "       6.93, 6.94, 6.95, 6.96, 6.97, 6.98, 6.99, 7.  , 7.01, 7.02, 7.03,\n",
       "       7.04, 7.05, 7.06, 7.07, 7.08, 7.09, 7.1 , 7.11, 7.12, 7.13, 7.14,\n",
       "       7.15, 7.16, 7.17, 7.18, 7.19, 7.2 , 7.21, 7.22, 7.23, 7.24, 7.25,\n",
       "       7.26, 7.27, 7.28, 7.29, 7.3 , 7.31, 7.32, 7.33, 7.34, 7.35, 7.36,\n",
       "       7.37, 7.38, 7.39, 7.4 , 7.41, 7.42, 7.43, 7.44, 7.45, 7.46, 7.47,\n",
       "       7.48, 7.49, 7.5 , 7.51, 7.52, 7.53, 7.54, 7.55, 7.56, 7.57, 7.58,\n",
       "       7.59, 7.6 , 7.61, 7.62, 7.63, 7.64, 7.65, 7.66, 7.67, 7.68, 7.69,\n",
       "       7.7 , 7.71, 7.72, 7.73, 7.74, 7.75, 7.76, 7.77, 7.78, 7.79, 7.8 ,\n",
       "       7.81, 7.82, 7.83, 7.84, 7.85, 7.86, 7.87, 7.88, 7.89, 7.9 , 7.91,\n",
       "       7.92, 7.93, 7.94, 7.95, 7.96, 7.97, 7.98, 7.99, 8.  , 8.01, 8.02,\n",
       "       8.03, 8.04, 8.05, 8.06, 8.07, 8.08, 8.09, 8.1 , 8.11, 8.12, 8.13,\n",
       "       8.14, 8.15, 8.16, 8.17, 8.18, 8.19, 8.2 , 8.21, 8.22, 8.23, 8.24,\n",
       "       8.25, 8.26, 8.27, 8.28, 8.29, 8.3 , 8.31, 8.32, 8.33, 8.34, 8.35,\n",
       "       8.36, 8.37, 8.38, 8.39, 8.4 , 8.41, 8.42, 8.43, 8.44, 8.45, 8.46,\n",
       "       8.47, 8.48, 8.49, 8.5 , 8.51, 8.52, 8.53, 8.54, 8.55, 8.56, 8.57,\n",
       "       8.58, 8.59, 8.6 , 8.61, 8.62, 8.63, 8.64, 8.65, 8.66, 8.67, 8.68,\n",
       "       8.69, 8.7 , 8.71, 8.72, 8.73, 8.74, 8.75, 8.76, 8.77, 8.78, 8.79,\n",
       "       8.8 , 8.81, 8.82, 8.83, 8.84, 8.85, 8.86, 8.87, 8.88, 8.89, 8.9 ,\n",
       "       8.91, 8.92, 8.93, 8.94, 8.95, 8.96, 8.97, 8.98, 8.99, 9.  , 9.01,\n",
       "       9.02, 9.03, 9.04, 9.05, 9.06, 9.07, 9.08, 9.09, 9.1 , 9.11, 9.12,\n",
       "       9.13, 9.14, 9.15, 9.16, 9.17, 9.18, 9.19, 9.2 , 9.21, 9.22, 9.23,\n",
       "       9.24, 9.25, 9.26, 9.27, 9.28, 9.29, 9.3 , 9.31, 9.32, 9.33, 9.34,\n",
       "       9.35, 9.36, 9.37, 9.38, 9.39, 9.4 , 9.41, 9.42, 9.43, 9.44, 9.45,\n",
       "       9.46, 9.47, 9.48, 9.49, 9.5 , 9.51, 9.52, 9.53, 9.54, 9.55, 9.56,\n",
       "       9.57, 9.58, 9.59, 9.6 , 9.61, 9.62, 9.63, 9.64, 9.65, 9.66, 9.67,\n",
       "       9.68, 9.69, 9.7 , 9.71, 9.72, 9.73, 9.74, 9.75, 9.76, 9.77, 9.78,\n",
       "       9.79, 9.8 , 9.81, 9.82, 9.83, 9.84, 9.85, 9.86, 9.87, 9.88, 9.89,\n",
       "       9.9 , 9.91, 9.92, 9.93, 9.94, 9.95, 9.96, 9.97, 9.98, 9.99])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0,1000) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:LLMICL]",
   "language": "python",
   "name": "conda-env-LLMICL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
